{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONS COMPILED\n",
      "\n",
      "LIBRARIES IMPORTED\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='fbref.com', port=443): Max retries exceeded with url: /en/matches/2023-03-10 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000221FBEEA888>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 157\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    751\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    993\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 169\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             )\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x00000221FBEEA888>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    719\u001b[0m             retries = retries.increment(\n\u001b[1;32m--> 720\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='fbref.com', port=443): Max retries exceeded with url: /en/matches/2023-03-10 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000221FBEEA888>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-769b355d5cea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://fbref.com/en/matches/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmatchday\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m \u001b[0mData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;31m#Parses site html data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='fbref.com', port=443): Max retries exceeded with url: /en/matches/2023-03-10 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000221FBEEA888>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "\n",
    "#This function extracts today's match links\n",
    "def hrefing(rawFixtures):\n",
    "    #counter\n",
    "    num = 0\n",
    "#list for storing the href wbelinks retrieved\n",
    "    todayFixtures = []\n",
    "\n",
    "    while num < len(rawFixtures):\n",
    "#assign variable name to a table data item inside rawFixture(rawFixtures contains many tables data) of html data\n",
    "        subsub= rawFixtures[num]\n",
    "#select 'a' tags \n",
    "        atags = subsub.find_all('a')\n",
    "#select the href links\n",
    "        hrefLinks = [l.get('href') for l in atags]\n",
    "#select href link bearing '/squads/'\n",
    "        hrefLinks = [l for l in hrefLinks if '/squads/'in l]\n",
    "#complete href link into weblink\n",
    "        hrefLinks = [\"https://fbref.com\"+l for l in hrefLinks]\n",
    "#append these weblinks to a list called todayFixtures \n",
    "        todayFixtures.append(hrefLinks)\n",
    "#add count\n",
    "        num+=1\n",
    "        \n",
    "    return (todayFixtures)\n",
    "\n",
    "\n",
    "\n",
    "#This function pairs elements in a list\n",
    "def pairer(fixtureLinks):\n",
    "    MatchPairs=[]\n",
    "#perform code for all items in fixtureLinks\n",
    "    for item in fixtureLinks:\n",
    "#append list pair into matchpairs list if length of list item is already a pair\n",
    "        if len(item) == 2:\n",
    "            MatchPairs.append(item)\n",
    "            \n",
    "#append list pair in match pair list if length of list item is bigger than a pair and a total even number \n",
    "        elif len(item) > 2 and len(item)%2 == 0:\n",
    "#As long as the number of list item is greater than 1;  move the first and second items of the list element into matchpairs list\n",
    "            while len(item) > 1:\n",
    "#pick the first and second item on list item and assign it to the variable called  first element\n",
    "                firstElement=item[0:2]\n",
    "#append first element to match pair then removes contents of first element from list item                \n",
    "                MatchPairs.append(firstElement)\n",
    "                item.pop(0)\n",
    "                item.pop(0)\n",
    "# skips any scenario that doesn't fall into the previous two conditions \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return MatchPairs\n",
    "\n",
    "\n",
    "\n",
    "#This function pairs elements in a list\n",
    "def h2hsingular(h2h_links):\n",
    "    h2h_links1=[]\n",
    "#perform code for all items in h2h_Links\n",
    "    for item in h2h_links:\n",
    "#append list pair into matchpairs list if length of list item is already a pair\n",
    "        if len(item) == 1:\n",
    "            h2h_links1.append(item)\n",
    "            \n",
    "#append list pair in match pair list if length of list item is bigger than a pair and a total even number \n",
    "        elif len(item) < 1:\n",
    "            x='pass'\n",
    "            h2h_links1.append(x)\n",
    "        else:            \n",
    "#As long as the number of list item is greater than 1;  move the first and second items of the list element into matchpairs list\n",
    "            while len(item) >= 1:\n",
    "#pick the first and second item on list item and assign it to the variable called  first element\n",
    "                firstElement=item[0]\n",
    "#append first element to match pair then removes contents of first element from list item                \n",
    "                h2h_links1.append(firstElement)\n",
    "                item.pop(0)\n",
    "\n",
    "    \n",
    "    return h2h_links1\n",
    "\n",
    "\n",
    "\n",
    "def all_strings(link_list):\n",
    "#list to be returned\n",
    "    new_linklist=[]\n",
    "#counter\n",
    "    num=0\n",
    "#check if elements in link_list are strings, if not convert to string\n",
    "    for a in link_list:\n",
    "#if element is a list, append the list's element into new_linklist\n",
    "        if type(a) == list:\n",
    "            x=link_list[num][0]\n",
    "            new_linklist.append(x)\n",
    "#if element is a string, append the string into new_linklist\n",
    "        elif type(a)== str:\n",
    "            new_linklist.append(a)\n",
    "#if element neither a string or a list append 'pass' to new_linklist\n",
    "        else:\n",
    "            new_linklist.append('pass')\n",
    "#count \n",
    "        num+=1\n",
    "    \n",
    "    return new_linklist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hrefing_h2h(rawFixtures):\n",
    "    #counter\n",
    "    num = 0\n",
    "    #href list\n",
    "    h2h_List = []\n",
    "    while num < len(rawFixtures):\n",
    "#assign variable name to a table data item inside rawFixtures (rawFixtures contains many tables data) of html data\n",
    "        subsub= rawFixtures[num]\n",
    "#select 'a' tags \n",
    "        atags = subsub.find_all('a')\n",
    "#select the href link\n",
    "        hrefLinks = [l.get('href') for l in atags]\n",
    "#select href link bearing '/stathead/'\n",
    "        hrefLinks = [l for l in hrefLinks if '/stathead/'in l]\n",
    "        hrefLinks = [\"https://fbref.com\"+l for l in hrefLinks]\n",
    "        h2h_List.append(hrefLinks)\n",
    "        num+=1\n",
    "    return (h2h_List)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this function takes in home & away team href links, for internet testing.  \n",
    "def home_away1(a):\n",
    "    #import libraries for time & datetime\n",
    "  \n",
    "    #retrieve homeTeam page html and assign it to the variable name called homeTeam\n",
    "    homeTeam=requests.get(a) \n",
    "    #wait for 4 seconds\n",
    "    homeDF = pd.read_html(homeTeam.text, match='Venue')[0]\n",
    "    homeDF=homeDF[['Date','Comp', 'Venue', 'Result', 'GF', 'GA', 'Opponent']]\n",
    "    matchDay = str(date.today())\n",
    "    #from homeDF, pick row which has the Date column data equal to today's date, assign that row to a new dataframe homeDF1\n",
    "    homeDF1 = homeDF[homeDF['Date'] == matchDay]\n",
    "    #reset the index column of homeDF1 to 0    \n",
    "    homeDF1 = homeDF1.reset_index(drop=True)\n",
    "    #retrieve the data under row = '0' and column = 'Comp'. then assign this value to a variable name called compName\n",
    "    compName=homeDF1.loc[0,'Comp']    \n",
    "    #In homeDF, drop all rows except where the 'Comp' column is equal to compName\n",
    "    homeDF = homeDF[homeDF['Comp'] == compName]\n",
    "    homeName = a.split('/')[-1].replace('-Stats','').replace('-',' ')\n",
    "    x= homeDF, homeName, compName\n",
    "    return x\n",
    "    \n",
    "#this function    \n",
    "def home_away2(b):\n",
    "    #import libraries for time & datetime\n",
    "      \n",
    "    #retrieve homeTeam page html and assign it to the variable name called homeTeam\n",
    "    \n",
    "    \n",
    "    #retrieve awayTeam page html and assign it to the variable name called awayTeam\n",
    "    awayTeam=requests.get(b) \n",
    "    \n",
    "    #using pandas, read homeTeam html and retrieve the match fixtures table in it (match fixture table is the only table with 'Venue'column), and assign table to dataframe name called homeDF\n",
    "    \n",
    "    #in homeDF, drop all columns except the specified ones\n",
    "    \n",
    "    #using pandas, read awayTeam html and retrieve the match fixtures table in it (match fixture table is the only table with 'Venue'column), and assign table to dataframe name called awayDF\n",
    "    awayDF = pd.read_html(awayTeam.text, match='Venue')[0]\n",
    "    #in awayDF, drop all columns except the specified ones\n",
    "    awayDF=awayDF[['Date','Comp', 'Venue', 'Result', 'GF', 'GA', 'Opponent']]\n",
    "    \n",
    "    #set variable matchDay as the string version of today's date\n",
    "    matchDay = str(date.today())\n",
    "    #from homeDF, pick row which has the Date column data equal to today's date, assign that row to a new dataframe homeDF1\n",
    "    awayDF1 = awayDF[awayDF['Date'] == matchDay]\n",
    "    #reset the index column of homeDF1 to 0    \n",
    "    awayDF1 = awayDF1.reset_index(drop=True)\n",
    "    #retrieve the data under row = '0' and column = 'Comp'. then assign this value to a variable name called compName\n",
    "    compName=awayDF1.loc[0,'Comp']    \n",
    "    #In homeDF, drop all rows except where the 'Comp' column is equal to compName\n",
    "    \n",
    "    #In awayDF, drop all rows except where the 'Comp' column is equal to compName\n",
    "    awayDF = awayDF[awayDF['Comp'] == compName]\n",
    "    \n",
    "    #from home team href link, retrieve club name and assign to a variable called homeName\n",
    "    \n",
    "    #from away team href link, retrieve club name and assign to a variable called awayName\n",
    "    awayName = b.split('/')[-1].replace('-Stats','').replace('-',' ')\n",
    "    #arrange homeDF, awayDF, awayName, compName in described order and put in a list called x\n",
    "    x= awayDF, awayName\n",
    "    return x\n",
    "\n",
    "\n",
    "#retrieve homeGenResult predictor value from df (homeDF) DataFrame\n",
    "def genrlCleaner(df):\n",
    "    #drop all rows that have None values\n",
    "    df = df.dropna(subset = ['Result'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    #retrieve number of rows remaining\n",
    "    x = int(df.shape[0])\n",
    "    #if number of rows is less than or equal to 5, \n",
    "    if x <= 5:\n",
    "        pass\n",
    "    #if no of rows is greater than 5\n",
    "    else:\n",
    "        #drop all rows except last five rows \n",
    "        df=df.head(5)\n",
    "    #create a reference dictionary where W=1, D=0.5, L=0\n",
    "    d = {'W': 1,'D': 0.5,'L': 0}\n",
    "    #replace the W, D, and L's in the 'Result' column with numbers based on the reference dictionary d\n",
    "    df['Result']=df['Result'].map(d)\n",
    "    #find the sum of the numbers in 'Result' column and assign the variable name v\n",
    "    v = float(df['Result'].sum())\n",
    "    \n",
    "    return v    \n",
    "\n",
    "        \n",
    "def homeCleaner(df):\n",
    "    df = df.dropna(subset = ['Result'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df[df['Venue']== 'Home']\n",
    "    x = int(df.shape[0])\n",
    "    if x <= 5:\n",
    "        pass\n",
    "    else:\n",
    "        df = df.head(5)\n",
    "    d={'W': 1,'D': 0.5,'L': 0}\n",
    "    df['Result']=df['Result'].map(d)\n",
    "    v=float(df['Result'].sum())\n",
    "    return v    \n",
    "            \n",
    "def awayCleaner(df):\n",
    "    df=df.dropna(subset = ['Result'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df= df[df['Venue']== 'Away']\n",
    "    x = int(df.shape[0])\n",
    "    if x<= 5:\n",
    "        pass\n",
    "    else:\n",
    "        n=x-5\n",
    "        df=df.head(5)\n",
    "    d={'W': 0,'D': 0.5,'L': 1}\n",
    "    df['Result']=df['Result'].map(d)\n",
    "    v=float(df['Result'].sum())\n",
    "    return v    \n",
    "\n",
    "def goals_home_away_Performance(link1, link2):\n",
    "    homepg = requests.get(link1)\n",
    "    awaypg = requests.get(link2)\n",
    "    DF1 = pd.read_html(homepg.text, match='Venue')[0]\n",
    "    DF2 = pd.read_html(awaypg.text, match='Venue')[0]\n",
    "\n",
    "    DF1 = DF1[['Date','Comp', 'Venue', 'Result', 'GF', 'GA', 'Opponent']]\n",
    "    DF2 = DF2[['Date','Comp', 'Venue', 'Result', 'GF', 'GA', 'Opponent']]\n",
    "\n",
    "    DF1 = DF1[DF1['Comp'] == num45]\n",
    "    DF2 = DF2[DF2['Comp'] == num45]\n",
    "    \n",
    "    DF1 = DF1.dropna(subset = ['Result'])\n",
    "    DF2 = DF2.dropna(subset = ['Result'])\n",
    "    \n",
    "    DF1 = DF1[DF1['Venue'] == 'Home']\n",
    "    DF2 = DF2[DF2['Venue'] == 'Away']\n",
    "\n",
    "    DF1 = DF1.tail(5)\n",
    "    DF2 = DF2.tail(5)\n",
    "\n",
    "    DF1 = DF1.reset_index(drop=True)\n",
    "    DF2 = DF2.reset_index(drop=True)\n",
    "\n",
    "    DF1['GF'] = DF1['GF'].astype(int)\n",
    "    DF2['GF'] = DF2['GF'].astype(int)\n",
    "\n",
    "    DF1['GA'] = DF1['GA'].astype(int)\n",
    "    DF2['GA'] = DF2['GA'].astype(int)\n",
    "\n",
    "    DF1['Point'] = (DF1['GF'] != 0).astype('int')\n",
    "    DF2['Point'] = (DF2['GA'] != 0).astype('int')\n",
    "\n",
    "    DF11 = DF1.tail(2)\n",
    "    DF11 = DF11.reset_index(drop=True)\n",
    "    DF11['Point'] = (DF11['GA'] != 0).astype('int')\n",
    "\n",
    "    DF12 = DF2.tail(2)\n",
    "    DF12 = DF12.reset_index(drop=True)\n",
    "    DF12['Point'] = (DF12['GF'] != 0).astype('int')\n",
    "\n",
    "    home_Score = sum(DF1['Point'])\n",
    "    away_Concede = sum(DF2['Point'])\n",
    "    home_Concede = sum(DF11['Point'])\n",
    "    away_Score = sum(DF1['Point'])\n",
    "    return home_Score, away_Concede, home_Concede, away_Score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#when to give a league link it returns the list of table standings in form of each team's page link \n",
    "def tableListing(leagueLink):\n",
    "    all_leagues = allcompetitions()\n",
    "    if leagueLink in all_leagues:\n",
    "        Data = requests.get(leagueLink)  \n",
    "        soup = bs.BeautifulSoup(Data.text)\n",
    "        tables= soup.select('table.stats_table')\n",
    "        x=list(tables)\n",
    "        tablelist=x[0]\n",
    "        tablelist=tablelist.find_all('a')\n",
    "        tablelist=[str(l) for l in tablelist]\n",
    "        tablelist=[l for l in tablelist if '/squads/' in l]\n",
    "        tablelist=[\"https://fbref.com\"+l.split('\"')[1] for l in tablelist]\n",
    "    else:\n",
    "        tablelist=[]\n",
    "        tablelist.append('pass')\n",
    "        \n",
    "    return tablelist\n",
    "\n",
    "\n",
    "#rank the two team on the table\n",
    "def teamRanker(tablelist,teamLink1,teamLink2):\n",
    "    if 'pass' not in tablelist:\n",
    "        tableRank1= tablelist.index(teamLink1)+1\n",
    "        tableRank2= tablelist.index(teamLink2)+1\n",
    "        tableNum= len(tablelist)\n",
    "    else:\n",
    "        tableRank1= 'pass'\n",
    "        tableRank2= 'pass'\n",
    "        tableNum= 'pass'\n",
    "    return(tableRank1,tableRank2,tableNum)\n",
    "    \n",
    "\n",
    "#generates league table links\n",
    "def leagueLkGenerator(rawFixtures):\n",
    "    dw=[]\n",
    "    da=[]\n",
    "#search in the table data for 'th' tags and append to list called dw. do this for all items in rawFIxtures\n",
    "    for a in rawFixtures:\n",
    "        b=a.find_all('th')\n",
    "        dw.append(b)\n",
    "#search the table 'th' data in dw for all 'a' tags, and  append to list called da\n",
    "    for a in dw:\n",
    "        for b in a:\n",
    "            c=b.find('a')\n",
    "            if c == None:\n",
    "                continue\n",
    "            else:\n",
    "                da.append(c)\n",
    "#convert da list content into strings\n",
    "    da = [str(l) for l in da]\n",
    "#convert da list content in complete links\n",
    "    competitionList = [\"https://fbref.com\"+l.split('\"')[1] for l in da]\n",
    "    \n",
    "    return (competitionList)\n",
    "\n",
    "#this functio pulls out all league competition Links\n",
    "def allcompetitions(allCompLink):\n",
    "    \n",
    "    compPg= requests.get(allCompLink)\n",
    "\n",
    "    soup=bs.BeautifulSoup(compPg.text)\n",
    "\n",
    "    atag=soup.find_all('a')\n",
    "\n",
    "    atag = list(atag)\n",
    "    atag = [str(l) for l in atag]\n",
    "    #atag = [l for l in atag if '/history/' in l]\n",
    "    #atag = [l.split('\"')[1] for l in atag]\n",
    "    #atag = ['https://fbref.com'+ l for l in atag]\n",
    "    #atag = [l.replace('history/','').replace('-Seasons','-Stats') for l in atag]\n",
    "    #ataga = atag[:116]\n",
    "    #atagx = ataga[32:]\n",
    "    return atag\n",
    "\n",
    "print('FUNCTIONS COMPILED\\n')\n",
    "\n",
    "#importing libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date\n",
    "import bs4 as bs\n",
    "import time\n",
    "\n",
    "print('LIBRARIES IMPORTED')\n",
    "\n",
    "matchday= str(date.today())\n",
    "#Download site data as html\n",
    "url = \"https://fbref.com/en/matches/\"+matchday\n",
    "\n",
    "Data = requests.get(url)\n",
    "\n",
    "#Parses site html data  \n",
    "soup = bs.BeautifulSoup(Data.text, features = 'html.parser')\n",
    "\n",
    "print('\\nSITE DATA RETRIEVED')\n",
    "\n",
    "#Select all tables named 'stats_table' and append to a list named 'rawFixtures'\n",
    "rawFixtures = soup.select('table.stats_table')\n",
    "\n",
    "#get the href links of each team in fixtures\n",
    "fixtureLinks = hrefing(rawFixtures)\n",
    "#pair team href links according to their exact match fixtures\n",
    "fixtureLinks = pairer(fixtureLinks)\n",
    "#In order to preserve the integrity of the main fixtureLinks, create dummy list called fixtureLinks0, that will be used to run subsequent codes\n",
    "fixtureLinks0 = fixtureLinks\n",
    "\n",
    "#retrieves league link for each match fixture in the today's matches page\n",
    "competitionList= leagueLkGenerator(rawFixtures)\n",
    "\n",
    "#retrieve all available h2h hrefLinks from each fixture\n",
    "h2h_links = hrefing_h2h(rawFixtures)\n",
    "#arrange each h2hlink as single elements\n",
    "h2h_links = h2hsingular(h2h_links)\n",
    "#convert all elements within the list into string object\n",
    "h2h_links = all_strings(h2h_links)\n",
    "\n",
    "print(\"TODAY'S FIXTURES EXTRACTED\")\n",
    "\n",
    "#retrieve home and away DataFrames, home and away names, and competition name and append to corresponding list\n",
    "homeDFlist=[]\n",
    "awayDFlist=[]\n",
    "homeNamelist=[]  #MAJOR\n",
    "awayNamelist=[]  #MAJOR\n",
    "compNamelist=[] #MAJOR\n",
    "#do this block of code for each element pair in fixtureLinks0\n",
    "print(str(len(fixtureLinks0))+' Potential Fixtures\\n\\n')\n",
    "for a in fixtureLinks0:\n",
    "    list_groupH=home_away1(a[0])\n",
    "    homeDFlist.append(list_groupH[0])\n",
    "    homeNamelist.append(list_groupH[1])\n",
    "    compNamelist.append(list_groupH[2])\n",
    "    list_groupA=home_away2(a[1])\n",
    "    awayDFlist.append(list_groupA[0])\n",
    "    awayNamelist.append(list_groupA[1])\n",
    "    #remove the first element pair form the fixtureLinks0 list, print number of element left in fixtureLinks0\n",
    "    #print(list_groupH[1] + ' vs ' + list_groupA[1])\n",
    "    time.sleep(1)\n",
    "    print('Fixture '+str(len(homeNamelist))+' extracted')\n",
    "print('Home DataFrame = ' +str(len(homeDFlist)))\n",
    "print('Away DataFrame = ' +str(len(awayDFlist)))\n",
    "print('homeNamelist = ' +str(len(homeNamelist)))\n",
    "print('awayNamelist = ' +str(len(awayNamelist)))\n",
    "print('compNamelist = ' +str(len(compNamelist)))\n",
    " \n",
    "print('DATAFRAMES EXTRACTED\\n')\n",
    "\n",
    "print('COMMENCING TEAM PERFORMANCE CALCULATIONS')\n",
    "\n",
    "h2hHomeName = []  #MAJOR\n",
    "\n",
    "#create predictor lists for all prediction parameters, later to be turned into columns of a final Dataframe\n",
    "homeResult = []  #MAJOR\n",
    "awayResult = []  #MAJOR\n",
    "homeGenResult = []  #MAJOR\n",
    "h2hResult = []  #MAJOR\n",
    "\n",
    "homeStanding = []  #MAJOR\n",
    "awayStanding = []  #MAJOR\n",
    "tableNum = []  #MAJOR\n",
    "\n",
    "#perform this for each dataframe within the list called homeDFlist\n",
    "for a in homeDFlist:\n",
    "#select the last 5 home matches in the dataframe, calculate the performance, and return the value as the variable homeValue\n",
    "    homeValue=homeCleaner(a)\n",
    "#append homeValue to its corresponding predictor list (homeResult)\n",
    "    homeResult.append(homeValue)\n",
    "\n",
    "#perform this for each dataframe within the list called awayDFlist    \n",
    "for a in awayDFlist:\n",
    "#select the last 5 away matches in the dataframe, calculate the performance, and return the value as the variable awayValue\n",
    "    awayValue=awayCleaner(a)\n",
    "#append awayValue to its corresponding predictor list (awayResult)\n",
    "    awayResult.append(awayValue)\n",
    "\n",
    "#perform this for each dataframe within the list called homeDFlist        \n",
    "for a in homeDFlist:\n",
    "#select the last 5 matches in the dataframe, calculate the performance, and return the value as the variable homeGen    \n",
    "    homeGen=genrlCleaner(a)\n",
    "#append homeGen to its corresponding predictor list (homeGenResult)\n",
    "    homeGenResult.append(homeGen)\n",
    "print(str(len(homeResult))+' homeResult SCORES CALCULATED')\n",
    "print(str(len(awayResult))+' awayResult SCORES CALCULATED')\n",
    "print(str(len(homeGenResult))+' homeGenResult SCORES CALCULATED')\n",
    "\n",
    "\n",
    "\n",
    "print('\\nEXTRACTING HEAD TO HEAD TABLES\\n...')\n",
    "\n",
    "h2hDFlist1 = []\n",
    "print(str(len(h2h_links))+ ' H2H tables found\\n\\n')\n",
    "for links in h2h_links:\n",
    "    pg = requests.get(links)\n",
    "    h2h_table = pd.read_html(pg.text, match = 'Head-to-Head Matches Table')[0]\n",
    "    h2h_table = h2h_table[['Home', 'Date','Score','Away']]\n",
    "    h2h_table['Score'] = [str(l) for l in h2h_table['Score']] \n",
    "    h2h_table = h2h_table[h2h_table['Score']!= 'nan']          \n",
    "    h2h_table = h2h_table.head(2)\n",
    "    h2h_table = h2h_table.reset_index(drop=True)\n",
    "    h2hDFlist1.append(h2h_table)\n",
    "    print('Transfered Tables = ' + str(len(h2hDFlist1)))\n",
    "    time.sleep(1)\n",
    "    \n",
    "\n",
    "\n",
    "h2hResult = []   #MAJOR\n",
    "h2hHomeName = []   #MAJOR\n",
    "for df in h2hDFlist1:\n",
    "    try:\n",
    "        df.loc[0, 'Home']\n",
    "    except:\n",
    "        h2hResult.append(1000)\n",
    "        h2hHomeName.append('pass')\n",
    "    else:\n",
    "        if df.loc[0,'Home'] == df.loc[df.shape[0] - 1,'Home']:\n",
    "            result=[]\n",
    "            num = 0\n",
    "            for a in df['Score']:\n",
    "                if '(' in a:\n",
    "                    hs = int(df.loc[num,'Score'][4])\n",
    "                    As = int(df.loc[num,'Score'][6])\n",
    "                    gd = hs - As\n",
    "                    result.append(gd)\n",
    "                else:\n",
    "                    hs = int(df.loc[num,'Score'][0])\n",
    "                    As = int(df.loc[num,'Score'][2])\n",
    "                    gd = hs - As\n",
    "                    result.append(gd)\n",
    "                num+=1\n",
    "            hn = df.loc[0, 'Home']\n",
    "            result = sum(result)\n",
    "        else:\n",
    "            result=[]\n",
    "            if '(' in df.loc[0,'Score']:\n",
    "                hs = int(df.loc[0, 'Score'][4])\n",
    "                As = int(df.loc[0, 'Score'][6])\n",
    "                gd = hs - As\n",
    "                result.append(gd)\n",
    "\n",
    "            else:\n",
    "                hs = int(df.loc[0, 'Score'][0])\n",
    "                As = int(df.loc[0, 'Score'][2])\n",
    "                gd = hs - As\n",
    "                result.append(gd)\n",
    "\n",
    "            if '(' in df.loc[1,'Score']:\n",
    "                hs = int(df.loc[1, 'Score'][6])\n",
    "                As = int(df.loc[1, 'Score'][4])\n",
    "                gd = hs - As\n",
    "                result.append(gd)\n",
    "\n",
    "            else: \n",
    "                hs = int(df.loc[1, 'Score'][2])\n",
    "                As = int(df.loc[1, 'Score'][0])\n",
    "                gd = hs - As\n",
    "                result.append(gd)\n",
    "            result = sum(result)\n",
    "            hn = df.loc[0, 'Home']\n",
    "        h2hResult.append(result)\n",
    "        h2hHomeName.append(hn)\n",
    "\n",
    "numm = 0\n",
    "for score in h2hResult:\n",
    "    if score == 0:\n",
    "        rez = 0.5\n",
    "        h2hResult[numm] = rez\n",
    "    elif score == 1000:\n",
    "        rez = 'pass'\n",
    "        h2hResult[numm] = rez\n",
    "    elif score > 0:\n",
    "        rez = 1\n",
    "        h2hResult[numm] = rez\n",
    "    elif score == 'pass':\n",
    "        rez = 'pass'\n",
    "        h2hResult[numm] = rez\n",
    "    else:\n",
    "        rez = 0\n",
    "        h2hResult[numm] = rez\n",
    "    numm+=1\n",
    "print(str(len(h2hResult)) + ' H2H SCORES CALCULATED')\n",
    "\n",
    "h2h_goal_list = []   #MAJOR\n",
    "for df in h2hDFlist1:\n",
    "    gtlist = []\n",
    "    num3 = 0\n",
    "    for a in df['Score']:\n",
    "        if '(' in a:\n",
    "            hs = int(df.loc[num3,'Score'][4])\n",
    "            As = int(df.loc[num3,'Score'][6])\n",
    "            gt = hs + As\n",
    "            gtlist.append(gt)\n",
    "        else:\n",
    "            hs = int(df.loc[num3,'Score'][0])\n",
    "            As = int(df.loc[num3,'Score'][2])\n",
    "            gt = hs + As\n",
    "            gtlist.append(gt)\n",
    "        num3 += 1\n",
    "    num4 = 0\n",
    "    for b in gtlist:\n",
    "        if b == 0:\n",
    "            gtlist[num4] = 0\n",
    "        else:\n",
    "            gtlist[num4] = 1\n",
    "        num4 += 1\n",
    "    h2hscore1 = sum(gtlist)\n",
    "    h2h_goal_list.append(h2hscore1)\n",
    "print('h2h Scores Calculated = '+str(len(h2h_goal_list)))\n",
    "\n",
    "home_GF = []\n",
    "away_GA = []\n",
    "home_GA = []\n",
    "away_GF = []\n",
    "\n",
    "num45 = 0\n",
    "for (a,b) in fixtureLinks:  \n",
    "    homepg = requests.get(a)\n",
    "    awaypg = requests.get(b)\n",
    "    DF1 = pd.read_html(homepg.text, match='Venue')[0]\n",
    "    DF2 = pd.read_html(awaypg.text, match='Venue')[0]\n",
    "\n",
    "    DF1 = DF1[['Date','Comp', 'Venue', 'Result', 'GF', 'GA', 'Opponent']]\n",
    "    DF2 = DF2[['Date','Comp', 'Venue', 'Result', 'GF', 'GA', 'Opponent']]\n",
    "\n",
    "    DF1 = DF1[DF1['Comp'] == compNamelist[num45]]\n",
    "    DF2 = DF2[DF2['Comp'] == compNamelist[num45]]\n",
    "    \n",
    "    DF1 = DF1.dropna(subset = ['Result'])\n",
    "    DF2 = DF2.dropna(subset = ['Result'])\n",
    "    \n",
    "    DF1 = DF1[DF1['Venue'] == 'Home']\n",
    "    DF2 = DF2[DF2['Venue'] == 'Away']\n",
    "\n",
    "    DF1 = DF1.tail(5)\n",
    "    DF2 = DF2.tail(5)\n",
    "\n",
    "    DF1 = DF1.reset_index(drop=True)\n",
    "    DF2 = DF2.reset_index(drop=True)\n",
    "\n",
    "    DF1['GF'] = DF1['GF'].astype(int)\n",
    "    DF2['GF'] = DF2['GF'].astype(int)\n",
    "\n",
    "    DF1['GA'] = DF1['GA'].astype(int)\n",
    "    DF2['GA'] = DF2['GA'].astype(int)\n",
    "\n",
    "    DF1['Point'] = (DF1['GF'] != 0).astype('int')\n",
    "    DF2['Point'] = (DF2['GA'] != 0).astype('int')\n",
    "\n",
    "    DF11 = DF1.tail(2)\n",
    "    DF11 = DF11.reset_index(drop=True)\n",
    "    DF11['Point'] = (DF11['GA'] != 0).astype('int')\n",
    "\n",
    "    DF12 = DF2.tail(2)\n",
    "    DF12 = DF12.reset_index(drop=True)\n",
    "    DF12['Point'] = (DF12['GF'] != 0).astype('int')\n",
    "\n",
    "    #home_Score = \n",
    "    #away_Concede = )\n",
    "    #home_Concede = )\n",
    "    #away_Score = )\n",
    "    home_GF.append(sum(DF1['Point']))\n",
    "    away_GA.append(sum(DF2['Point']))\n",
    "    home_GA.append(sum(DF11['Point']))\n",
    "    away_GF.append(sum(DF12['Point']))\n",
    "    num45+=1\n",
    "    print('Fixture '+str(len(home_GF))+ ' Goal Records Calculated' )\n",
    "    time.sleep(2)\n",
    "\n",
    "print('\\n\\nCOMPILING FINAL DATAFRAME\\n')\n",
    "_tbl = {(' ','HOME'): homeNamelist, (' ','AWAY'): awayNamelist, (' ','COMP'): compNamelist, ('1 X','HOME FORM'): homeResult, ('1 X','AWAY FORM'): awayResult, ('1 X','HOME GEN FORM'): homeGenResult, ('1 X','h2h HOME'): h2hHomeName, ('1 X','H2H FORM'): h2hResult, ('OVER 0.5','HOME TO SCORE'): home_GF, ('OVER 0.5','AWAY TO CONCEDE'): away_GA, ('OVER 0.5','HOME TO CONCEDE'): home_GA, ('OVER 0.5','AWAY TO SCORE'): away_GF, ('OVER 0.5','H2H GOAL'): h2h_goal_list }\n",
    "Final_DF = pd.DataFrame(_tbl)\n",
    "\n",
    "\n",
    "Final_DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
